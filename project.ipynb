{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md413FzAvFD8"
      },
      "source": [
        "# DX 704 Week 4 Project\n",
        "\n",
        "This week's project will test the learning speed of linear contextual bandits compared to unoptimized approaches.\n",
        "You will start with building a preference data set for evaluation, and then implement different variations of LinUCB and visualize how fast they learn the preferences.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3gs-tquuzJe"
      },
      "source": [
        "The full project description, a template notebook and supporting code are available on GitHub: [Project 4 Materials](https://github.com/bu-cds-dx704/dx704-project-04).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OguIjc5idW3Z"
      },
      "source": [
        "## Example Code\n",
        "\n",
        "You may find it helpful to refer to these GitHub repositories of Jupyter notebooks for example code.\n",
        "\n",
        "* https://github.com/bu-cds-omds/dx601-examples\n",
        "* https://github.com/bu-cds-omds/dx602-examples\n",
        "* https://github.com/bu-cds-omds/dx603-examples\n",
        "* https://github.com/bu-cds-omds/dx704-examples\n",
        "\n",
        "Any calculations demonstrated in code examples or videos may be found in these notebooks, and you are allowed to copy this example code in your homework answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8oSLkMqvMFF"
      },
      "source": [
        "## Part 1: Collect Rating Data\n",
        "\n",
        "The file \"recipes.tsv\" in this repository has information about 100 recipes.\n",
        "Make a new file \"ratings.tsv\" with two columns, recipe_slug (from recipes.tsv) and rating.\n",
        "Populate the rating column with values between 0 and 1 where 0 is the worst and 1 is the best.\n",
        "You can assign these ratings however you want within that range, but try to make it reflect a consistent set of preferences.\n",
        "These could be your preferences, or a persona of your choosing (e.g. chocolate lover, bacon-obsessed, or sweet tooth).\n",
        "Make sure that there are at least 10 ratings of zero and at least 10 ratings of one.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAwViBgKfWER"
      },
      "source": [
        "Hint: You may find it more convenient to assign raw ratings from 1 to 5 and then remap them as follows.\n",
        "\n",
        "`ratings[\"rating\"] = (ratings[\"rating_raw\"] - 1) * 0.25`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "recipes = pd.read_csv(\"recipes.tsv\", sep=\"\\t\")\n",
        "recipe_tags = pd.read_csv(\"recipe-tags.tsv\", sep=\"\\t\")\n",
        "\n",
        "favor_keywords = {\"eggs\", \"cheese\", \"healthy\", \"fruit\", \"sushi\", \"ramen\", \"hearty\", \"avocado\", \"vegetarian\", \"italian\", \"salsa\", \"burger\", \"tomatoes\", \"spicy\", \"garlic\", \"beef\", \"chicken\"}\n",
        "disfavor_keywords = {\"spam\", \"bacon\", \"dessert\", \"fudgy\", \"chocolate\", \"frosting\", \"sugar\", \"pie\"}\n",
        "\n",
        "tag_counts = recipe_tags.groupby(\"recipe_slug\")[\"recipe_tag\"].apply(list)\n",
        "\n",
        "def assign_raw_rating(tags):\n",
        "    tags = set(tags)\n",
        "    score = 3  \n",
        "    if tags & favor_keywords:\n",
        "        score += 1\n",
        "    if tags & disfavor_keywords:\n",
        "        score -= 1\n",
        "    return min(max(score, 1), 5)\n",
        "\n",
        "recipes[\"rating_raw\"] = recipes[\"recipe_slug\"].map(lambda slug: assign_raw_rating(tag_counts.get(slug, [])))\n",
        "\n",
        "recipes.loc[:9, \"rating_raw\"] = 1   \n",
        "recipes.loc[10:19, \"rating_raw\"] = 5  \n",
        "\n",
        "recipes[\"rating\"] = (recipes[\"rating_raw\"] - 1) * 0.25\n",
        "\n",
        "ratings = recipes[[\"recipe_slug\", \"rating\"]]\n",
        "ratings.to_csv(\"ratings.tsv\", sep=\"\\t\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh7UaX6OvuWo"
      },
      "source": [
        "Submit \"ratings.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiCwaZwr5M67"
      },
      "source": [
        "## Part 2: Construct Model Input\n",
        "\n",
        "Use your file \"ratings.tsv\" combined with \"recipe-tags.tsv\" to create a new file \"features.tsv\" with a column recipe_slug, a column bias which is hard-coded to one, and a column for each tag that appears in \"recipe-tags.tsv\".\n",
        "The tag column in this file should be a 0-1 encoding of the recipe tags for each recipe.\n",
        "[Pandas reshaping function methods](https://pandas.pydata.org/docs/user_guide/reshaping.html) may be helpful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WWi_JJXocEb"
      },
      "source": [
        "The bias column will make later LinUCB calculations easier since it will just be another dimension."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHR-BsD9539j"
      },
      "source": [
        "Hint: For later modeling steps, it will be important to have the feature data (inputs) and the rating data (target outputs) in the same order.\n",
        "It is highly recommended to make sure that \"features.tsv\" and \"ratings.tsv\" have the recipe slugs in the same order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "cGvj258d8nnv"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "recipe_tags = pd.read_csv(\"recipe-tags.tsv\", sep=\"\\t\")\n",
        "\n",
        "ratings = pd.read_csv(\"ratings.tsv\", sep=\"\\t\")\n",
        "\n",
        "tag_matrix = (\n",
        "    recipe_tags\n",
        "    .assign(value=1)\n",
        "    .pivot_table(index=\"recipe_slug\", columns=\"recipe_tag\", values=\"value\", fill_value=0)\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "tag_matrix[\"bias\"] = 1\n",
        "\n",
        "cols = [\"recipe_slug\", \"bias\"] + sorted([col for col in tag_matrix.columns if col not in [\"recipe_slug\", \"bias\"]])\n",
        "features = tag_matrix[cols]\n",
        "\n",
        "features = ratings[[\"recipe_slug\"]].merge(features, on=\"recipe_slug\", how=\"left\")\n",
        "\n",
        "assert (features[\"recipe_slug\"] == ratings[\"recipe_slug\"]).all()\n",
        "\n",
        "features.to_csv(\"features.tsv\", sep=\"\\t\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w63ji-Oi6oH7"
      },
      "source": [
        "Submit \"features.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TeXvznlwJzo"
      },
      "source": [
        "## Part 3: Linear Preference Model\n",
        "\n",
        "Use your feature and rating files to build a ridge regression model with ridge regression's regularization parameter $\\alpha$ set to 1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVlUnVv4oDIk"
      },
      "source": [
        "Hint: If you are using scikit-learn modeling classes, you should use `fit_intercept=False` since that intercept value will be redundant with the bias coefficient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLrBu-z7A45W"
      },
      "source": [
        "Hint: The estimate component of the bounds should match the previous estimate, so you should be able to just focus on the variance component of the bounds now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "dxtiRunPwPYz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model trained. MSE: 0.0045, R²: 0.9448\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "features = pd.read_csv(\"features.tsv\", sep=\"\\t\").sort_values(\"recipe_slug\").reset_index(drop=True)\n",
        "ratings = pd.read_csv(\"ratings.tsv\", sep=\"\\t\").sort_values(\"recipe_slug\").reset_index(drop=True)\n",
        "\n",
        "features = features.sort_values(\"recipe_slug\").reset_index(drop=True)\n",
        "ratings = ratings.sort_values(\"recipe_slug\").reset_index(drop=True)\n",
        "\n",
        "X = features.drop(columns=[\"recipe_slug\"])\n",
        "\n",
        "y = ratings[\"rating\"]\n",
        "\n",
        "model = Ridge(alpha=1.0, fit_intercept=False)\n",
        "\n",
        "model.fit(X, y)\n",
        "\n",
        "predictions = model.predict(X)\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "mse = mean_squared_error(y, predictions)\n",
        "r2 = r2_score(y, predictions)\n",
        "\n",
        "print(f\"Model trained. MSE: {mse:.4f}, R²: {r2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fw9LaHF_8tsA"
      },
      "source": [
        "Save the coefficients of this model in a file \"model.tsv\" with columns \"recipe_tag\" and \"coefficient\".\n",
        "Do not add anything for the `intercept_` attribute of a scikit-learn model; this will be covered by the coefficient for the bias column added in part 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fiMBlU4L8uSR"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "\n",
        "model = Ridge(alpha=1.0, fit_intercept=False)\n",
        "model.fit(X, y)\n",
        "\n",
        "feature_names = X.columns\n",
        "\n",
        "coefficients = model.coef_\n",
        "\n",
        "model_df = pd.DataFrame({\n",
        "    \"recipe_tag\": feature_names,\n",
        "    \"coefficient\": coefficients\n",
        "})\n",
        "\n",
        "model_df.to_csv(\"model.tsv\", sep=\"\\t\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86uS_zZ0wQxC"
      },
      "source": [
        "Submit \"model.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1Nfs7zCsDpj"
      },
      "source": [
        "## Part 4: Recipe Estimates\n",
        "\n",
        "Use the recipe model to estimate the score of every recipe.\n",
        "Save these estimates to a file \"estimates.tsv\" with columns recipe_slug and score_estimate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "pIClPwYVso5a"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "features = pd.read_csv(\"features.tsv\", sep=\"\\t\").sort_values(\"recipe_slug\").reset_index(drop=True)\n",
        "ratings = pd.read_csv(\"ratings.tsv\", sep=\"\\t\").sort_values(\"recipe_slug\").reset_index(drop=True)\n",
        "\n",
        "X = features.drop(columns=[\"recipe_slug\"])\n",
        "recipe_slugs = features[\"recipe_slug\"]\n",
        "\n",
        "y = ratings[\"rating\"]\n",
        "model = Ridge(alpha=1.0, fit_intercept=False)\n",
        "model.fit(X, y)\n",
        "\n",
        "score_estimates = model.predict(X)\n",
        "\n",
        "estimates_df = pd.DataFrame({\n",
        "    \"recipe_slug\": recipe_slugs,\n",
        "    \"score_estimate\": score_estimates\n",
        "})\n",
        "\n",
        "estimates_df.to_csv(\"estimates.tsv\", sep=\"\\t\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5t3uSE_srMA"
      },
      "source": [
        "Submit \"estimates.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTBplNhRst8q"
      },
      "source": [
        "## Part 5: LinUCB Bounds\n",
        "\n",
        "Calculate the upper bounds of LinUCB using data corresponding to trying every recipe once and receiving the rating in \"ratings.tsv\" as the reward.\n",
        "Keep the ridge regression regularization parameter at 1, and set LinUCB's $\\alpha$ parameter to 2.\n",
        "Save these upper bounds to a file \"bounds.tsv\" with columns recipe_slug and score_bound."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "kY7aWD_PuP0W"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "features_df = pd.read_csv(\"features.tsv\", sep=\"\\t\")\n",
        "ratings_df = pd.read_csv(\"ratings.tsv\", sep=\"\\t\")\n",
        "\n",
        "X = features_df.drop(columns=[\"recipe_slug\"]).values \n",
        "y = ratings_df[\"rating\"].values                       \n",
        "\n",
        "\n",
        "lambda_ = 1\n",
        "alpha = 2\n",
        "\n",
        "\n",
        "A = X.T @ X + lambda_ * np.identity(X.shape[1])  \n",
        "b = X.T @ y                                     \n",
        "\n",
        "A_inv = np.linalg.inv(A)\n",
        "\n",
        "\n",
        "theta_hat = A_inv @ b  \n",
        "\n",
        "\n",
        "score_bounds = []\n",
        "for x in X:\n",
        "    x = x.reshape(-1, 1)  \n",
        "    mean_estimate = float((theta_hat @ x)[0])\n",
        "    uncertainty = float(np.sqrt((x.T @ A_inv @ x)[0,0]))\n",
        "    bound = mean_estimate + alpha * uncertainty\n",
        "    score_bounds.append(bound)\n",
        "\n",
        "\n",
        "bounds_df = pd.DataFrame({\n",
        "    \"recipe_slug\": features_df[\"recipe_slug\"],\n",
        "    \"score_bound\": score_bounds\n",
        "})\n",
        "bounds_df.to_csv(\"bounds.tsv\", sep=\"\\t\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQ4RPppFvG-S"
      },
      "source": [
        "Submit \"bounds.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfazOSWlwYsP"
      },
      "source": [
        "## Part 6: Make Online Recommendations\n",
        "\n",
        "Implement LinUCB to make 100 recommendations starting with no data and using the same parameters as in part 5.\n",
        "One recommendation should be made at a time and you can break ties arbitrarily.\n",
        "After each recommendation, use the rating from part 1 as the reward to update the LinUCB data.\n",
        "Record the recommendations made in a file \"recommendations.tsv\" with columns \"recipe_slug\", \"score_bound\", and \"reward\".\n",
        "The rows in this file should be in the same order as the recommendations were made."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "hQ7r45B7wm4v"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "features_df = pd.read_csv(\"features.tsv\", sep=\"\\t\")\n",
        "ratings_df = pd.read_csv(\"ratings.tsv\", sep=\"\\t\")\n",
        "\n",
        "X_all = features_df.drop(columns=[\"recipe_slug\"]).values  \n",
        "recipe_slugs = features_df[\"recipe_slug\"].tolist()\n",
        "ratings = ratings_df.set_index(\"recipe_slug\")[\"rating\"].to_dict()\n",
        "\n",
        "lambda_ = 1\n",
        "alpha = 2\n",
        "n_features = X_all.shape[1]\n",
        "\n",
        "A = lambda_ * np.identity(n_features)\n",
        "b = np.zeros((n_features,))\n",
        "\n",
        "recommended = set()\n",
        "\n",
        "recommendation_log = []\n",
        "\n",
        "for t in range(100):\n",
        "    best_bound = -np.inf\n",
        "    best_index = None\n",
        "    best_x = None\n",
        "\n",
        "    A_inv = np.linalg.inv(A)\n",
        "    theta_hat = A_inv @ b\n",
        "\n",
        "    for i, (slug, x) in enumerate(zip(recipe_slugs, X_all)):\n",
        "        if slug in recommended:\n",
        "            continue\n",
        "\n",
        "        x_vec = x.reshape(-1, 1)\n",
        "        mean = float(theta_hat @ x)\n",
        "        uncertainty = float(np.sqrt((x_vec.T @ A_inv @ x_vec) [0,0]))\n",
        "        bound = mean + alpha * uncertainty\n",
        "\n",
        "        if bound > best_bound:\n",
        "            best_bound = bound\n",
        "            best_index = i\n",
        "            best_x = x\n",
        "\n",
        "    chosen_slug = recipe_slugs[best_index]\n",
        "    reward = ratings[chosen_slug]\n",
        "\n",
        "    x = best_x.reshape(-1, 1)\n",
        "    A += x @ x.T\n",
        "    b += reward * best_x\n",
        "\n",
        "    recommendation_log.append({\n",
        "        \"recipe_slug\": chosen_slug,\n",
        "        \"score_bound\": best_bound,\n",
        "        \"reward\": reward\n",
        "    })\n",
        "\n",
        "    recommended.add(chosen_slug)\n",
        "\n",
        "recommendations_df = pd.DataFrame(recommendation_log)\n",
        "recommendations_df.to_csv(\"recommendations.tsv\", sep=\"\\t\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23jv0cD0woSt"
      },
      "source": [
        "Submit \"recommendations.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi8lV2pbvWMs"
      },
      "source": [
        "## Part 7: Acknowledgments\n",
        "\n",
        "Make a file \"acknowledgments.txt\" documenting any outside sources or help on this project.\n",
        "If you discussed this assignment with anyone, please acknowledge them here.\n",
        "If you used any libraries not mentioned in this module's content, please list them with a brief explanation what you used them for.\n",
        "If you used any generative AI tools, please add links to your transcripts below, and any other information that you feel is necessary to comply with the generative AI policy.\n",
        "If no acknowledgements are appropriate, just write none in the file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "acknowledgements = [\n",
        "['1. https://github.com/BartyzalRadek/contextual-bandits-recommender/blob/master/linUCB.py', \n",
        " 'To learn more about linUCB code especially the vectors and alorgithm behind it.'],\n",
        "['2. https://github.com/umeshksingla/news-recommend-ire/blob/master/src/imbalanced_classification.py',\n",
        " 'To look at repos that implements LinUCB'],\n",
        " ['3. https://github.com/niffler92/Bandit/blob/master/bandit/bandit.py', 'To learn more about contextual bandits'],\n",
        " ['4. https://wensun.github.io/CS6789_data/linUCB.pdf', 'To learn more about the formulas discuss in class about the linUCB Linear Upper Confidence Bound']\n",
        "]\n",
        "\n",
        "columns = ['Source', 'Used For/Reason']\n",
        "\n",
        "ack_df = pd.DataFrame(acknowledgements, columns=columns)\n",
        "\n",
        "ack_df.to_csv(\"acknowledgements.txt\", sep=\"\\t\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuNJe62UxCoH"
      },
      "source": [
        "Submit \"acknowledgments.txt\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smsTLuFcvR-I"
      },
      "source": [
        "## Part 8: Code\n",
        "\n",
        "Please submit a Jupyter notebook that can reproduce all your calculations and recreate the previously submitted files.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cgzHyF7wxpr"
      },
      "source": [
        "Submit \"project.ipynb\" in Gradescope."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": false
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
